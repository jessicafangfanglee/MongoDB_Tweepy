{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "myclient = pymongo.MongoClient(\"mongodb://127.0.0.1:27017/\")\n",
    "mydb = myclient['example_database']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admin', 'config', 'local', 'test']\n"
     ]
    }
   ],
   "source": [
    "print(myclient.list_database_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new mongo host\n",
    "MONGO_HOST = 'mongodb://localhost/twitterdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_host = pymongo.MongoClient(MONGO_HOST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = new_host.twitterdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admin', 'config', 'local', 'test']\n"
     ]
    }
   ],
   "source": [
    "print(new_host.list_database_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'twitterdb')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSUMER_KEY = \"uOipYxIgXPvhm9hwJdIrRt7Om\"\n",
    "CONSUMER_SECRET = \"xmtYD4VDc6qIDrvkQ3RWEJROma20OAgZgDLAynoMIrkKgE70F6\"\n",
    "ACCESS_TOKEN = \"822684512500862976-CpC6XW5Vo38UHC3py94wqS7UJwmQjpl\"\n",
    "ACCESS_TOKEN_SECRET = \"g8soWB7r6MlsHvbzQeuBN0TU3nq0wJh98utp7X9MZzu2a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweepy\n",
      "  Downloading https://files.pythonhosted.org/packages/d5/5f/daac4b4e9b30d7d2a6fdd16a880ff79f27918fe388e4dfc1983dec3a9876/tweepy-3.7.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests>=2.11.1 in /Users/flee/anaconda3/lib/python3.7/site-packages (from tweepy) (2.21.0)\n",
      "Collecting requests-oauthlib>=0.7.0 (from tweepy)\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/e2/9fd03d55ffb70fe51f587f20bcf407a6927eb121de86928b34d162f0b1ac/requests_oauthlib-1.2.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/flee/anaconda3/lib/python3.7/site-packages (from tweepy) (1.12.0)\n",
      "Requirement already satisfied: PySocks>=1.5.7 in /Users/flee/anaconda3/lib/python3.7/site-packages (from tweepy) (1.6.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/flee/anaconda3/lib/python3.7/site-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/flee/anaconda3/lib/python3.7/site-packages (from requests>=2.11.1->tweepy) (1.24.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/flee/anaconda3/lib/python3.7/site-packages (from requests>=2.11.1->tweepy) (2019.3.9)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/flee/anaconda3/lib/python3.7/site-packages (from requests>=2.11.1->tweepy) (2.8)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->tweepy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/95/699466b05b72b94a41f662dc9edf87fda4289e3602ecd42d27fcaddf7b56/oauthlib-3.0.1-py2.py3-none-any.whl (142kB)\n",
      "\u001b[K    100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 143kB 6.8MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: oauthlib, requests-oauthlib, tweepy\n",
      "Successfully installed oauthlib-3.0.1 requests-oauthlib-1.2.0 tweepy-3.7.0\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '\"#ETH\" or \"#Etherium\"'\n",
    "max_tweets = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@tylerwinklevoss #tezos is #etherium 2.0. It matches or beats #eth across the board. It‚Äôs market cap is ~1 bil, #eth market cap is ~28bil. Do the math!\n",
      "\n",
      "#xtz #flippening #blockchain @Gemini üëç\n",
      "Tweet no: 0\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for status in tweepy.Cursor(api.search, q=query, lang='en', tweet_mode='extended').items(max_tweets):\n",
    "    tweetjson = status._json\n",
    "    db.twitter_search_ETH.insert_one(tweetjson)\n",
    "    print(tweetjson['full_text'])\n",
    "    print(\"Tweet no:\",i)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 17 12:51:44 +0000 2019\n",
      "RT @goodfellow_ian: OctConv is a simple replacement for the traditional convolution operation that gets better accuracy with fewer FLOPs ht‚Ä¶\n",
      "Tue Apr 02 13:23:50 +0000 2019\n",
      "RT @paperswithcode: Top in Trending: official code for StyleGAN is out. StyleGAN achieves state-of-the-art results on CelebA-HQ and FFHQ da‚Ä¶\n",
      "Tue Apr 02 13:16:57 +0000 2019\n",
      "RT @ipfconline1: 5 New Generative Adversarial Network (GAN) Architectures For Image Synthesis\n",
      "üëá\n",
      "Now we can generate high-resolution, realis‚Ä¶\n",
      "Mon Apr 01 21:20:31 +0000 2019\n",
      "RT @slashML: Genetic algorithm to find optimal neural network structure which uses backprop https://t.co/s5V86VDuSe\n",
      "Wed Mar 13 16:03:08 +0000 2019\n",
      "@randal_olson True that. Sometimes I feel it is taking forever to update even small packages.\n",
      "Sun Mar 03 16:17:20 +0000 2019\n",
      "RT @gp_pulipaka: Deploying PyTorch and #Keras Models to #Android with #TensorFlow Mobiles. #BigData #Analytics #DataScience #AI #MachineLea‚Ä¶\n",
      "Tue Feb 26 13:52:11 +0000 2019\n",
      "RT @slashML: PyTorch Implementation of Feature Based NER with pretrained Bert https://t.co/B6LOLqZVKg\n",
      "Sat Feb 23 05:53:33 +0000 2019\n",
      "Creativity the most important skill to survive. I think this has been the case throughout the history of mankind. https://t.co/EkfBnMNGS7\n",
      "Sat Feb 23 05:50:07 +0000 2019\n",
      "RT @Ronald_vanLoon: The positive impact of #ArtificialIntelligence on our future\n",
      "via @wef |\n",
      " \n",
      "#AI #ML #MachineLearning #DL #DeepLearning #E‚Ä¶\n",
      "Sat Feb 23 05:47:12 +0000 2019\n",
      "RT @DataScienceCtrl: Data Scientist Skill Set https://t.co/Cq4XoAN4j4\n",
      "Sat Feb 23 05:41:41 +0000 2019\n",
      "RT @rajat_shrimal: This #AI program is so good that its dangerous to release it to public\n",
      "\n",
      "#ArtificialIntelligence #machinelearning #Automa‚Ä¶\n",
      "Sat Feb 23 05:38:53 +0000 2019\n",
      "RT @KirkDBorne: Download the most fabulous R Cheat Sheets designed by @Rstudio ‚Äî https://t.co/eY55zVyXI7 #abdsc\n",
      "‚Äî‚Äî‚Äî‚Äî\n",
      "#BigData #DataScience‚Ä¶\n",
      "Sat Feb 23 05:35:39 +0000 2019\n",
      "RT @MikeTamir: Generalized Language Models https://t.co/RBvWeFa48o #AI #DeepLearning #MachineLearning #DataScience https://t.co/54vBJmTMQO\n",
      "Fri Feb 15 16:33:25 +0000 2019\n",
      "RT @gneubig: #ICLR2019 paper on \"Multilingual Neural Machine Translation with Soft Decoupled Encoding\". A better way to perform lexical tra‚Ä¶\n",
      "Fri Feb 15 16:29:24 +0000 2019\n",
      "RT @davidwbressler: I used BERT as a pretrained model to build a Wikipedia natural language search engine (https://t.co/4Ji1iszCyr). A @fas‚Ä¶\n",
      "Fri Feb 15 15:41:31 +0000 2019\n",
      "RT @gp_pulipaka: Facebook Releases PyText NLP Modeling Framework. #BigData #Analytics #MachineLearning #DataScience #AI #NLProc #IoT #IIoT‚Ä¶\n",
      "Fri Feb 15 15:39:54 +0000 2019\n",
      "RT @kunalpatel085: How #5G will change the world https://t.co/qAdNd4tqIS via @wef\n",
      " \n",
      "@Tiffani_Bova @KirkDBorne @jblefevre60 @Ronald_vanLoon‚Ä¶\n",
      "Mon Feb 11 16:08:39 +0000 2019\n",
      "RT @DataScienceCtrl: 100+ Commonly Asked Data Science Interview Questions https://t.co/mUd5UF5zz5\n",
      "Mon Feb 11 16:04:25 +0000 2019\n",
      "RT @simonlporter: AI Trends In 2019 - https://t.co/Oua1VELyyz\n",
      "Mon Feb 11 16:04:18 +0000 2019\n",
      "RT @analyticbridge: Google releases massive visual databases for machine learning https://t.co/Z6682GCHGA\n",
      "Fri Feb 01 22:51:24 +0000 2019\n",
      "RT @paperswithcode: We‚Äôve just released the new Papers With Code! Site now has over 950+ ML tasks, 500+ evaluation tables (including state‚Ä¶\n",
      "Fri Feb 01 20:23:05 +0000 2019\n",
      "From @jeremiecharris's article. 2 things to keep in mind when looking for a job.\n",
      "1. Optimize the crap out of your resume.\n",
      "2. Try to skip the resume screening step altogether.\n",
      "Sat Jan 26 06:05:22 +0000 2019\n",
      "RT @DataScienceCtrl: Facebook Shares Large Data Sets to Help Improve its AI and Data Science Algorithms https://t.co/OikX6QfERu\n",
      "Sat Jan 26 06:03:00 +0000 2019\n",
      "RT @jeremyphoward: Practical Deep Learning for Coders, 2019 edition, is now available. With a shiny new video player with searchable transc‚Ä¶\n",
      "Fri Jan 25 16:59:06 +0000 2019\n",
      "RT @KirkDBorne: #Alibaba's #AI can generate 20,000 lines of copy in a second, and has even passed the #TuringTest: https://t.co/heJ2DGPzHa‚Ä¶\n",
      "Wed Jan 16 04:22:19 +0000 2019\n",
      "RT @KirkDBorne: 40+ Techniques Used by #DataScientists, with links to articles for every one of the techniques: https://t.co/VBNBR1bn91 #ab‚Ä¶\n",
      "Tue Jan 15 17:39:31 +0000 2019\n",
      "RT @TopCyberNews: #CES2019 #QuantumComputer!\n",
      "\n",
      "cc: @SPittWalker @ipfconline1 @SpirosMargaris @andi_staub @sallyeaves @HaroldSinnott @mclynd‚Ä¶\n",
      "Tue Jan 15 17:37:04 +0000 2019\n",
      "RT @KirkDBorne: #AI predictions for 2019 from Yann LeCun, Hilary Mason, Andrew Ng, and Rumman Chowdhury: https://t.co/xjzWut69uF\n",
      "\n",
      "#MachineL‚Ä¶\n",
      "Tue Jan 15 03:32:23 +0000 2019\n",
      "RT @odsc: The 50 best public datasets for #MachineLearning https://t.co/fjaauUN6ui\n",
      "Tue Jan 15 03:30:21 +0000 2019\n",
      "RT @FinMKTG: Disrupt or be disrupted - inside CEO‚Äôs brain üß† \n",
      "#DigitalTransformation #fintech #futureofwork \n",
      "\n",
      "HT @MikeQuindazzi v/ @helene_w‚Ä¶\n",
      "Tue Jan 15 03:30:03 +0000 2019\n",
      "RT @kaggle: 10 Predictions for Deep Learning in 2019 by  @IntuitMachine https://t.co/GgWF76Xjiq https://t.co/4FGJd8qp4l\n",
      "Thu Jan 10 17:36:17 +0000 2019\n",
      "RT @KirkDBorne: Continuous lifelong learning empowered with this Reading List for #DataScientists\n",
      "https://t.co/FVvs54Tttu #abdsc\n",
      "\n",
      "#BigData‚Ä¶\n",
      "Wed Jan 09 21:12:58 +0000 2019\n",
      "RT @alvinfoo: 7 Trends at #CES2019 \n",
      "\n",
      "#5G #smarthome #IOT #wearables #AutonomousVehicles #AR #DigitalTransformation \n",
      "\n",
      "@alison_iot @ipfconlin‚Ä¶\n",
      "Tue Jan 08 04:31:34 +0000 2019\n",
      "RT @PyImageSearch: New tutorial!üöÄ Auto-Keras and AutoML: A Getting Started Guide\n",
      "- Automatically create + train #DeepLearning models\n",
      "- Zero‚Ä¶\n",
      "Tue Jan 08 04:30:18 +0000 2019\n",
      "RT @ipfconline1: One of The Greatest 2018 #MachineLearning Paper\n",
      "üëá\n",
      "Large-Scale Study of Curiosity-Driven Learning\n",
      "\n",
      "https://t.co/VYNy1lcYRc‚Ä¶\n",
      "Tue Jan 08 04:30:07 +0000 2019\n",
      "RT @simonlporter: 3 basic steps to start-up your AI Business Strategy https://t.co/MlhbFUj40K\n",
      "Mon Jan 07 04:05:26 +0000 2019\n",
      "RT @KirkDBorne: Demystifying #AI ‚Äî Explained In One Picture!\n",
      "\n",
      "+plus see more #BigData #DataScience \"Explained in One Picture\" articles and‚Ä¶\n",
      "Mon Dec 31 04:34:56 +0000 2018\n",
      "RT @MikeQuindazzi: #AI prepares to #HACK your brain &gt;&gt;&gt; @MikeQuindazzi &gt;&gt;&gt; #MachineLearning #DeepLearning #IoT #BigData #DataAnalytics #Mal‚Ä¶\n",
      "Mon Dec 31 04:34:42 +0000 2018\n",
      "RT @simonlporter: 50+ Examples of How Blockchains are Taking Over the World https://t.co/RV3c9j9lSd\n",
      "Sat Dec 29 05:22:52 +0000 2018\n",
      "RT @DD_Wen_: What Great Data Analysts Do ‚Äî and Why Every Organization Needs Them \n",
      "https://t.co/BLD71Z6ZbR\n",
      "Sat Dec 29 05:19:47 +0000 2018\n",
      "RT @analyticbridge: Swarm Optimization: Goodbye Gradients https://t.co/QV4dQ9LxtB\n",
      "Sat Dec 29 05:18:54 +0000 2018\n",
      "RT @MHiesboeck: üî¥ Can you imagine 200 quadrillion calculations per second üß†?\n",
      "\n",
      "@antgrasso @jeffkagan @psb_dc @cloudpreacher @DrJDrooghaag @F‚Ä¶\n",
      "Wed Dec 26 07:15:21 +0000 2018\n",
      "For us the learning will continue lifelong. https://t.co/FDQfoNpzwS\n",
      "Wed Dec 26 07:12:46 +0000 2018\n",
      "RT @TamaraMcCleary: Want to be a #DataScientist? 25 #DataScience skills. #MachineLearning #BigData #DataMining #Statistics #Cloud #programm‚Ä¶\n",
      "Wed Dec 26 07:12:22 +0000 2018\n",
      "RT @KirkDBorne: 7 Techniques for Data Dimensionality Reduction for #DataScientists: https://t.co/mGsy68rhiQ #abdsc \n",
      "\n",
      "#BigData #DataScience‚Ä¶\n",
      "Tue Dec 25 23:10:00 +0000 2018\n",
      "RT @KirkDBorne: Top Trends &amp; Expectations for #AI in 2019: https://t.co/aDLYkE992K by @analyticsinme HT @DeepLearn007 \n",
      "\n",
      "#XAI #MachineLearni‚Ä¶\n",
      "Mon Dec 24 14:31:53 +0000 2018\n",
      "RT @KirkDBorne: 4 Strategies to Deal With Large Datasets Using Pandas: https://t.co/J37CIh9x8e #DataScience #MachineLearning #BigData #Codi‚Ä¶\n",
      "Sun Dec 23 13:37:52 +0000 2018\n",
      "RT @IBMDeveloper: Get the Code: Use deep-learning algorithms to detect movement, and identify objects in a video feed. https://t.co/OMPwJV2‚Ä¶\n",
      "Sun Dec 23 13:36:53 +0000 2018\n",
      "RT @Ronald_vanLoon: #AI can be used to create a ‚Äòmaster key‚Äô that will fool fingerprint scanners.\n",
      "by @nowthisnews @MasterprintUK |\n",
      "\n",
      "#Artifi‚Ä¶\n",
      "Sat Dec 22 20:52:15 +0000 2018\n",
      "RT @NicolasPapernot: Our team @GoogleAI has just released a new library for training machine learning models with (differential) privacy fo‚Ä¶\n",
      "Sat Dec 22 20:51:49 +0000 2018\n",
      "RT @SamueL_WonG_: How Fast Is Artificial Intelligence Growing? Look At The Key Bellwethers via @forbes https://t.co/1s4JEV7mDi\n",
      "Sat Dec 22 20:51:03 +0000 2018\n",
      "I have always loved the idea of swarm robots..practical and efficient ...  better than humanoids https://t.co/okh5C8jruJ\n",
      "Sat Dec 22 20:48:54 +0000 2018\n",
      "Python it is. https://t.co/IaeH5xOR8Z\n",
      "Sat Dec 22 20:48:05 +0000 2018\n",
      "RT @KirkDBorne: The Ten Best Programming Languages to learn in 2019: https://t.co/AqaNfMSBTP #python #Rstats #java #javascript #coding #Dat‚Ä¶\n",
      "Sat Dec 22 20:47:47 +0000 2018\n",
      "RT @sheena2804: Great People to follow :\n",
      "#FF\n",
      "\n",
      "@evankirstel @SpirosMargaris @TamaraMcCleary @antgrasso  @ipfconline1 @JacBurns_Comext @MikeQ‚Ä¶\n",
      "Sat Dec 22 20:47:27 +0000 2018\n",
      "RT @BillGates: The books that kept me up reading in 2018: https://t.co/Up1rwhXV4G https://t.co/yaoBHNV4gR\n",
      "Sat Dec 22 20:46:42 +0000 2018\n",
      "RT @slashML: How do you keep track of all the updates in your field? Research, techniques, and programming. Very time consuming ‚Ä¶ https://t‚Ä¶\n",
      "Sat Dec 22 20:46:03 +0000 2018\n",
      "This is what we need in our cities https://t.co/akPsXHKSSk\n",
      "Sat Dec 22 20:44:23 +0000 2018\n",
      "RT @KirkDBorne: Breaking Through the Cost Barrier to #DeepLearning with Transfer Learning: https://t.co/s0RnuYNp95 #abdsc #BigData #DataSci‚Ä¶\n",
      "Thu Dec 20 12:38:03 +0000 2018\n",
      "RT @KirkDBorne: Top 20 #Python libraries for #DataScience in 2018: https://t.co/5dDTXZ0rzP #abdsc #Infographic by @ActiveWizards\n",
      "\n",
      "#BigData‚Ä¶\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec 20 12:36:11 +0000 2018\n",
      "RT @simonlporter: What The AI Jobs Of The Future Will Look Like https://t.co/xUiXQadLx3\n",
      "Thu Dec 20 12:35:22 +0000 2018\n",
      "RT @KirkDBorne: 5 trends to expect for artificial intelligence in 2019: https://t.co/cNfcjkXlbw #DeepLearning #MachineLearning #DataScience‚Ä¶\n",
      "Tue Dec 18 20:39:47 +0000 2018\n",
      "RT @TamaraMcCleary: Want to be a #DataScientist? 25 #DataScience skills. #MachineLearning #BigData #DataMining #Statistics #Cloud #programm‚Ä¶\n",
      "Tue Dec 18 12:21:55 +0000 2018\n",
      "RT @simonlporter: What Data Scientists Really Do, According to 35 Data Scientists https://t.co/mKFBQweNGH\n",
      "Tue Dec 18 12:21:42 +0000 2018\n",
      "RT @KirkDBorne: Cheat Sheets for #DataScientists ‚Äî #DataScience, #MachineLearning, #Statistics, #DeepLearning, #DataViz +more (including R,‚Ä¶\n",
      "Mon Dec 17 13:34:45 +0000 2018\n",
      "RT @dataandme: ü§ì Oh so handy...\n",
      "\"Stanford CS 229 machine learning cheatsheets\"  üë¨ @afshinea &amp; @shervinea\n",
      "https://t.co/VKV2UGkWzN #MachineLe‚Ä¶\n",
      "Mon Dec 17 13:34:34 +0000 2018\n",
      "RT @DataCamp: This handy one-page cheat sheet presents the #Python basics that you need to perform data analysis!\n",
      "https://t.co/X2hUn97nqW h‚Ä¶\n",
      "Mon Dec 17 13:31:34 +0000 2018\n",
      "RT @simonlporter: A.I. and robotics will create almost 60 million more jobs than they destroy by 2022, report says https://t.co/gWOIamyBuY\n",
      "Mon Dec 17 13:31:19 +0000 2018\n",
      "RT @analyticbridge: 33 unusual problems that can be solved with data science https://t.co/fmCpOOXZB1\n",
      "Mon Dec 17 13:29:43 +0000 2018\n",
      "RT @KirkDBorne: Check out the 150+ excellent #DeepLearning resources, articles, infographics, and tutorials for #DataScientists that are av‚Ä¶\n",
      "Sat Dec 15 04:34:18 +0000 2018\n",
      "RT @slashML: Beyond imitation: Zero-shot task transfer on robots by learning concepts as cognitive programs https://t.co/g3vyL3mZ80\n",
      "Sat Dec 15 04:33:59 +0000 2018\n",
      "RT @DD_Wen_: Getting Value from Machine Learning Isn‚Äôt About Fancier Algorithms ‚Äî It‚Äôs About Making It Easier to Use \n",
      "https://t.co/i24Ix9ta‚Ä¶\n",
      "Sat Dec 15 01:46:06 +0000 2018\n",
      "@KirkDBorne Been following your tweets for some time now. Must say...really good reasearch...A must follow for anyone interested in #Datascience #MachineLearning #AI Truly deserved No 1 spot.\n",
      "Sat Dec 15 01:43:36 +0000 2018\n",
      "RT @KirkDBorne: Colossal Collection of Cool &amp; Convenient Cheat Sheets for Curious #DataScientists ‚Äî #DataScience, #MachineLearning, #Statis‚Ä¶\n",
      "Sat Dec 15 01:40:27 +0000 2018\n",
      "Now this is what we need in every school around the globe. https://t.co/TvDEAuQ8UP\n",
      "Fri Dec 14 16:39:07 +0000 2018\n",
      "RT @AndrewYNg: The AI Index 2018 report is out! Lots of great data. My key takeaways: (i) AI's rapid growth--in jobs, publications, perform‚Ä¶\n",
      "Fri Dec 14 15:30:49 +0000 2018\n",
      "RT @kdnuggets: A radical new #neuralnetwork design could solve #AI problems where data is continuous. \"Neural Ordinary Differential Equatio‚Ä¶\n",
      "Fri Dec 14 15:29:48 +0000 2018\n",
      "RT @Ronald_vanLoon: In 4 years your #Smartphone might be able to read your mind\n",
      "by @wef @IRO_ITB |\n",
      "\n",
      "#ArtificialIntelligence #AI #SmartTech‚Ä¶\n",
      "Fri Dec 14 15:27:32 +0000 2018\n",
      "RT @KirkDBorne: The #DataScience Mindmap for Managers: https://t.co/AXcaaq28q9 #abdsc \n",
      "\n",
      "#Analytics #BigData #DataAnalytics #AI #DAIFE #Mach‚Ä¶\n",
      "Thu Dec 13 11:33:11 +0000 2018\n",
      "RT @MHiesboeck: These are the most innovative and impactful #technologies around\n",
      "\n",
      "@chboursin @alvinfoo @kashthefuturist @MarTechExec @gratt‚Ä¶\n",
      "Thu Dec 13 01:11:58 +0000 2018\n",
      "RT @BillGates: This book is a must read for anyone interested in AI, machine learning, and machine vision. https://t.co/bOFgrnkORN\n",
      "Thu Dec 13 01:07:36 +0000 2018\n",
      "RT @DataScienceCtrl: 25 Timeless Data Science Articles https://t.co/IyBNpkCTCA\n",
      "Wed Dec 12 00:16:40 +0000 2018\n",
      "RT @HaroldSinnott: üó£Ô∏èJack Ma : The best way to promote your company is not you, the #CEO. The best way is your product, your services and y‚Ä¶\n",
      "Wed Dec 12 00:10:04 +0000 2018\n",
      "Highly useful!! https://t.co/YXu3bgO4RD\n",
      "Wed Dec 12 00:08:10 +0000 2018\n",
      "The Catch-22 for aspiring data scientists, I quote @_brohrer_ \"New data scientists can‚Äôt show their qualifications because they‚Äôve never had a data science job, and they can‚Äôt get a data science job because they can‚Äôt show their qualifications.\"\n",
      "Wed Dec 12 00:03:23 +0000 2018\n",
      "So General Adversarial Networks and AutoML seem to be the things to watch out for in 2019. https://t.co/0qGf5FQhPd\n",
      "Tue Dec 11 23:52:32 +0000 2018\n",
      "RT @schmarzo: Here's how #millennials should view the world of #DataScience. @HitachiVantara @CloudExpo @ipfconline1\n",
      "https://t.co/EAaH0hw1p‚Ä¶\n",
      "Tue Dec 11 23:46:10 +0000 2018\n",
      "RT @ipfconline1: The 4 Types of Artificial Intelligence: From Reactive to Self-Aware [Infographic]\n",
      "https://t.co/AgXBj9Aeir       v/ @Futuri‚Ä¶\n",
      "Tue Dec 11 21:11:54 +0000 2018\n",
      "RT @KirkDBorne: How To Start A #Startup (#Infographic) and Beginners Guide to Being an #Entrepreneur : https://t.co/ezIBFQSzKI by @ineedseo‚Ä¶\n",
      "Sat Dec 08 14:53:03 +0000 2018\n",
      "RT @KirkDBorne: #Blockchain infographic ‚Äî 50+ real use cases: https://t.co/EhD7FKkDWE #abdsc #bitcoin #SmartContracts #DistributedLedger #D‚Ä¶\n",
      "Thu Dec 06 13:30:22 +0000 2018\n",
      "So these are the top skills-\n",
      "Programming : Python, JAVA, C++\n",
      "Statistical : Scala , SAS, R\n",
      "Visualization: Tableau\n",
      "Deep Learning: Tensorflow, PyTorch, Keras\n",
      "Data Engineering: SQL, Spark, Hadoop\n",
      "\n",
      "Great insights by George Liu https://t.co/WLs7A9Gix9\n",
      "Thu Dec 06 13:05:16 +0000 2018\n",
      "RT @alvinfoo: #AI will add $16 trillion to the global economy by 2030!\n",
      "\n",
      "#Fintech #Retail #DigitalTransformation #FutureofWork #iot\n",
      "\n",
      "@MicWon‚Ä¶\n",
      "Thu Dec 06 13:05:06 +0000 2018\n",
      "RT @chboursin: #WearableTech screen wraps around your arm &gt;&gt;&gt; @futurism via @MikeQuindazzi &gt;&gt;&gt; #Innovation #Mobile #IoT #AI #Wearables #5G‚Ä¶\n",
      "Sat Dec 01 21:35:32 +0000 2018\n",
      "RT @Ronald_vanLoon: These 100 Companies Are Leading the Way in A.I.\n",
      "by @nick_rapp @brianbokeefe @FortuneMagazine |\n",
      "\n",
      "#MachineLearning #ML #D‚Ä¶\n",
      "Sat Dec 01 21:30:35 +0000 2018\n",
      "Excellent !! https://t.co/bNjjQ1fkVB\n",
      "Sat Dec 01 11:57:07 +0000 2018\n",
      "So true üòÇüòÇ https://t.co/jmLm88in8P\n",
      "Tue Nov 27 01:46:01 +0000 2018\n",
      "RT @grattonboy: Ten types of #AI technologies advancing in 2018 @MikeQuindazzi #ArtificialIntelligence #AI #DeepLearning MT @jblefevre60‚û°Ô∏èh‚Ä¶\n",
      "Tue Nov 27 01:43:35 +0000 2018\n",
      "RT @Ronald_vanLoon: A china-made holographic #3D projection device will be showcased\n",
      "by @CCTV_Plus |\n",
      "\n",
      "#InternetOfThings #IoT #Smarttech #3D‚Ä¶\n",
      "Mon Nov 26 18:30:50 +0000 2018\n",
      "RT @DataScienceCtrl: What pays most: R, Python, or SQL? https://t.co/BJVXDttvZp\n",
      "Mon Nov 26 18:30:27 +0000 2018\n",
      "RT @KirkDBorne: The 2018 #BigData and #AI Landscape: https://t.co/J58CCQKmNy by @MattTurck \n",
      "\n",
      "#DataScience #Analytics #MachineLearning #Deep‚Ä¶\n",
      "Fri Nov 23 14:49:12 +0000 2018\n",
      "RT @KirkDBorne: 20 Great Articles about #AI, #MachineLearning, and #DeepLearning: https://t.co/pwCoRw7bLd #abdsc \n",
      "\n",
      "#BigData #DataScience #N‚Ä¶\n",
      "Fri Nov 23 14:45:37 +0000 2018\n",
      "@randal_olson Excellent\n",
      "Fri Nov 23 14:44:27 +0000 2018\n",
      "RT @odsc: Take a look into Uber‚Äôs Michelangelo PyML, a platform that enables rapid Python ML model development. #AI #ODSC https://t.co/xs3V‚Ä¶\n",
      "Tue Nov 20 23:34:40 +0000 2018\n",
      "RT @KirkDBorne: Breakthrough Neural Network paves the way for Quantum #AI: https://t.co/h9z6V4disj\n",
      "\n",
      "Read more about it here: https://t.co/D‚Ä¶\n",
      "Mon Nov 19 13:19:07 +0000 2018\n",
      "RT @odsc: Deloitte: ‚ÄòPervasive‚Äô AI promises to transform agriculture, health care, and manufacturing #AI #ODSC https://t.co/mW1pVsV5qJ\n",
      "Mon Nov 19 11:59:31 +0000 2018\n",
      "RT @KirkDBorne: Comprehensive Repository of #DataScience Resources, including ‚ÄúFour Great Pictures Illustrating #MachineLearning Concepts‚Äù‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for status in tweepy.Cursor(api.user_timeline, screename='elonmusk', tweet_mode='extended').items(200):\n",
    "    print(status._json['created_at'])\n",
    "    print(status._json['full_text'])\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRUD operations with MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycollection = mydb['example_collection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(Database(MongoClient(host=['127.0.0.1:27017'], document_class=dict, tz_aware=False, connect=True), 'example_database'), 'get_collection_names')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydb.get_collection_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x10e465f08>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inserting one example data \n",
    "example_customer_data = {'name': 'John Doe', 'address': '123 elm street', 'age': 28}\n",
    "\n",
    "results = mycollection.insert_one(example_customer_data)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectId('5ce2075e3db6e237bea7a69b')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.inserted_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserting many entries at the same time\n",
    "customer_2 = {'name': 'Jane Doe', 'address': '234 elm street', 'age': 7}\n",
    "customer_3 = {'name': 'Santa Claus', 'address': 'The North Pole', 'age': 547}\n",
    "customer_4 = {'name': 'John Doe jr.', 'address': '', 'age': 0.5}\n",
    "\n",
    "list_of_customers = [customer_2, customer_3, customer_4]\n",
    "\n",
    "results_2 = mycollection.insert_many(list_of_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ObjectId('5ce2078a3db6e237bea7a69c'),\n",
       " ObjectId('5ce2078a3db6e237bea7a69d'),\n",
       " ObjectId('5ce2078a3db6e237bea7a69e')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2.inserted_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5ce2075e3db6e237bea7a69b'), 'name': 'John Doe', 'address': '123 elm street', 'age': 28}\n",
      "{'_id': ObjectId('5ce2078a3db6e237bea7a69c'), 'name': 'Jane Doe', 'address': '234 elm street', 'age': 7}\n",
      "{'_id': ObjectId('5ce2078a3db6e237bea7a69d'), 'name': 'Santa Claus', 'address': 'The North Pole', 'age': 547}\n",
      "{'_id': ObjectId('5ce2078a3db6e237bea7a69e'), 'name': 'John Doe jr.', 'address': '', 'age': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# querying the data in the db\n",
    "query_1 = mycollection.find({})\n",
    "for x in query_1:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5ce2075e3db6e237bea7a69b'), 'name': 'John Doe'}\n",
      "{'_id': ObjectId('5ce2078a3db6e237bea7a69c'), 'name': 'Jane Doe'}\n",
      "{'_id': ObjectId('5ce2078a3db6e237bea7a69d'), 'name': 'Santa Claus'}\n",
      "{'_id': ObjectId('5ce2078a3db6e237bea7a69e'), 'name': 'John Doe jr.'}\n"
     ]
    }
   ],
   "source": [
    "# querying more data in the db\n",
    "query_2 = mycollection.find({}, {'name': 1})\n",
    "for item in query_2:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though Mongo stores each record like a JSON file, it is quite efficient. What MongoDB actually stores is a binary representation of this piece of record. In the below entry, we can see the sections as a predefined join with the outer document. We can call the sections embedded. This document structure of the database allows flexibility and speed. \n",
    "\n",
    "`\n",
    "{\n",
    "   _id: ObjectId(8af37bd7891c)\n",
    "   title: 'MongoDB Lab', \n",
    "   description: 'Introductory lab on how to use MongoDB',\n",
    "   by: 'Flatiron School',\n",
    "   topics: ['mongodb', 'database', 'NoSQL', 'JSON'], \n",
    "   sections: [\t\n",
    "      {\n",
    "         section:'Introduction',\n",
    "         dateCreated: new Date(2019,3,1),\n",
    "         reading_time_minutes: 1 \n",
    "      },\n",
    "      {\n",
    "         user:'Installing and Running MongoDB',\n",
    "         dateCreated: new Date(2019,3,1),\n",
    "         reading_time_minutes: 5\n",
    "      }\n",
    "      {\n",
    "         user:'Examining a Sample MongoDB Record',\n",
    "         dateCreated: new Date(2019,3,1),\n",
    "         reading_time_minutes: 8\n",
    "      }\n",
    "   ]\n",
    "}\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
