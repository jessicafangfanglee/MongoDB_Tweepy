{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONGO_HOST = 'mongodb://localhost/twitterdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSUMER_KEY = \"uOipYxIgXPvhm9hwJdIrRt7Om\"\n",
    "CONSUMER_SECRET = \"xmtYD4VDc6qIDrvkQ3RWEJROma20OAgZgDLAynoMIrkKgE70F6\"\n",
    "ACCESS_TOKEN = \"822684512500862976-CpC6XW5Vo38UHC3py94wqS7UJwmQjpl\"\n",
    "ACCESS_TOKEN_SECRET = \"g8soWB7r6MlsHvbzQeuBN0TU3nq0wJh98utp7X9MZzu2a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(MONGO_HOST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client.twitterdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '\"#ETH\" or \"#Etherium\"'\n",
    "max_tweets = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ServerSelectionTimeoutError",
     "evalue": "localhost:27017: [Errno 61] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServerSelectionTimeoutError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8137a73bd0f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'extended'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_tweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtweetjson\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtwitter_search_ETH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweetjson\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m#print(tweetjson['full_text'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tweet no:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pymongo/collection.py\u001b[0m in \u001b[0;36minsert_one\u001b[0;34m(self, document, bypass_document_validation, session)\u001b[0m\n\u001b[1;32m    691\u001b[0m                          \u001b[0mwrite_concern\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwrite_concern\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                          \u001b[0mbypass_doc_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbypass_document_validation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m                          session=session),\n\u001b[0m\u001b[1;32m    694\u001b[0m             write_concern.acknowledged)\n\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pymongo/collection.py\u001b[0m in \u001b[0;36m_insert\u001b[0;34m(self, docs, ordered, check_keys, manipulate, write_concern, op_id, bypass_doc_val, session)\u001b[0m\n\u001b[1;32m    605\u001b[0m             return self._insert_one(\n\u001b[1;32m    606\u001b[0m                 \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanipulate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_concern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 bypass_doc_val, session)\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pymongo/collection.py\u001b[0m in \u001b[0;36m_insert_one\u001b[0;34m(self, doc, ordered, check_keys, manipulate, write_concern, op_id, bypass_doc_val, session)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         self.__database.client._retryable_write(\n\u001b[0;32m--> 595\u001b[0;31m             acknowledged, _insert_command, session)\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRawBSONDocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m_retryable_write\u001b[0;34m(self, retryable, func, session)\u001b[0m\n\u001b[1;32m   1245\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_retryable_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretryable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m         \u001b[0;34m\"\"\"Internal retryable write helper.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tmp_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1248\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retry_with_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretryable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m_tmp_session\u001b[0;34m(self, session, close)\u001b[0m\n\u001b[1;32m   1574\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1576\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1577\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m_ensure_session\u001b[0;34m(self, session)\u001b[0m\n\u001b[1;32m   1561\u001b[0m             \u001b[0;31m# Don't make implicit sessions causally consistent. Applications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m             \u001b[0;31m# should always opt-in.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__start_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcausal_consistency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1564\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mConfigurationError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInvalidOperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m             \u001b[0;31m# Sessions not supported, or multiple users authenticated.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m__start_session\u001b[0;34m(self, implicit, **kwargs)\u001b[0m\n\u001b[1;32m   1514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m         \u001b[0;31m# Raises ConfigurationError if sessions are not supported.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1516\u001b[0;31m         \u001b[0mserver_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_server_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1517\u001b[0m         \u001b[0mopts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSessionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1518\u001b[0m         return client_session.ClientSession(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m_get_server_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_server_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1548\u001b[0m         \u001b[0;34m\"\"\"Internal: start or resume a _ServerSession.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1549\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_topology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_server_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_return_server_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pymongo/topology.py\u001b[0m in \u001b[0;36mget_server_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    425\u001b[0m                             \u001b[0many_server_selector\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_selection_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m                             None)\n\u001b[0m\u001b[1;32m    428\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_description\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadable_servers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                     self._select_servers_loop(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pymongo/topology.py\u001b[0m in \u001b[0;36m_select_servers_loop\u001b[0;34m(self, selector, timeout, address)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 raise ServerSelectionTimeoutError(\n\u001b[0;32m--> 199\u001b[0;31m                     self._error_message(selector))\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_opened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mServerSelectionTimeoutError\u001b[0m: localhost:27017: [Errno 61] Connection refused"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for status in tweepy.Cursor(api.search, q=query, lang='en', tweet_mode='extended').items(max_tweets):\n",
    "    tweetjson = status._json\n",
    "    db.twitter_search_ETH.insert_one(tweetjson)\n",
    "    #print(tweetjson['full_text'])\n",
    "    print(\"Tweet no:\",i)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 17 12:51:44 +0000 2019\n",
      "RT @goodfellow_ian: OctConv is a simple replacement for the traditional convolution operation that gets better accuracy with fewer FLOPs ht…\n",
      "Tue Apr 02 13:23:50 +0000 2019\n",
      "RT @paperswithcode: Top in Trending: official code for StyleGAN is out. StyleGAN achieves state-of-the-art results on CelebA-HQ and FFHQ da…\n",
      "Tue Apr 02 13:16:57 +0000 2019\n",
      "RT @ipfconline1: 5 New Generative Adversarial Network (GAN) Architectures For Image Synthesis\n",
      "👇\n",
      "Now we can generate high-resolution, realis…\n",
      "Mon Apr 01 21:20:31 +0000 2019\n",
      "RT @slashML: Genetic algorithm to find optimal neural network structure which uses backprop https://t.co/s5V86VDuSe\n",
      "Wed Mar 13 16:03:08 +0000 2019\n",
      "@randal_olson True that. Sometimes I feel it is taking forever to update even small packages.\n",
      "Sun Mar 03 16:17:20 +0000 2019\n",
      "RT @gp_pulipaka: Deploying PyTorch and #Keras Models to #Android with #TensorFlow Mobiles. #BigData #Analytics #DataScience #AI #MachineLea…\n",
      "Tue Feb 26 13:52:11 +0000 2019\n",
      "RT @slashML: PyTorch Implementation of Feature Based NER with pretrained Bert https://t.co/B6LOLqZVKg\n",
      "Sat Feb 23 05:53:33 +0000 2019\n",
      "Creativity the most important skill to survive. I think this has been the case throughout the history of mankind. https://t.co/EkfBnMNGS7\n",
      "Sat Feb 23 05:50:07 +0000 2019\n",
      "RT @Ronald_vanLoon: The positive impact of #ArtificialIntelligence on our future\n",
      "via @wef |\n",
      " \n",
      "#AI #ML #MachineLearning #DL #DeepLearning #E…\n",
      "Sat Feb 23 05:47:12 +0000 2019\n",
      "RT @DataScienceCtrl: Data Scientist Skill Set https://t.co/Cq4XoAN4j4\n",
      "Sat Feb 23 05:41:41 +0000 2019\n",
      "RT @rajat_shrimal: This #AI program is so good that its dangerous to release it to public\n",
      "\n",
      "#ArtificialIntelligence #machinelearning #Automa…\n",
      "Sat Feb 23 05:38:53 +0000 2019\n",
      "RT @KirkDBorne: Download the most fabulous R Cheat Sheets designed by @Rstudio — https://t.co/eY55zVyXI7 #abdsc\n",
      "————\n",
      "#BigData #DataScience…\n",
      "Sat Feb 23 05:35:39 +0000 2019\n",
      "RT @MikeTamir: Generalized Language Models https://t.co/RBvWeFa48o #AI #DeepLearning #MachineLearning #DataScience https://t.co/54vBJmTMQO\n",
      "Fri Feb 15 16:33:25 +0000 2019\n",
      "RT @gneubig: #ICLR2019 paper on \"Multilingual Neural Machine Translation with Soft Decoupled Encoding\". A better way to perform lexical tra…\n",
      "Fri Feb 15 16:29:24 +0000 2019\n",
      "RT @davidwbressler: I used BERT as a pretrained model to build a Wikipedia natural language search engine (https://t.co/4Ji1iszCyr). A @fas…\n",
      "Fri Feb 15 15:41:31 +0000 2019\n",
      "RT @gp_pulipaka: Facebook Releases PyText NLP Modeling Framework. #BigData #Analytics #MachineLearning #DataScience #AI #NLProc #IoT #IIoT…\n",
      "Fri Feb 15 15:39:54 +0000 2019\n",
      "RT @kunalpatel085: How #5G will change the world https://t.co/qAdNd4tqIS via @wef\n",
      " \n",
      "@Tiffani_Bova @KirkDBorne @jblefevre60 @Ronald_vanLoon…\n",
      "Mon Feb 11 16:08:39 +0000 2019\n",
      "RT @DataScienceCtrl: 100+ Commonly Asked Data Science Interview Questions https://t.co/mUd5UF5zz5\n",
      "Mon Feb 11 16:04:25 +0000 2019\n",
      "RT @simonlporter: AI Trends In 2019 - https://t.co/Oua1VELyyz\n",
      "Mon Feb 11 16:04:18 +0000 2019\n",
      "RT @analyticbridge: Google releases massive visual databases for machine learning https://t.co/Z6682GCHGA\n",
      "Fri Feb 01 22:51:24 +0000 2019\n",
      "RT @paperswithcode: We’ve just released the new Papers With Code! Site now has over 950+ ML tasks, 500+ evaluation tables (including state…\n",
      "Fri Feb 01 20:23:05 +0000 2019\n",
      "From @jeremiecharris's article. 2 things to keep in mind when looking for a job.\n",
      "1. Optimize the crap out of your resume.\n",
      "2. Try to skip the resume screening step altogether.\n",
      "Sat Jan 26 06:05:22 +0000 2019\n",
      "RT @DataScienceCtrl: Facebook Shares Large Data Sets to Help Improve its AI and Data Science Algorithms https://t.co/OikX6QfERu\n",
      "Sat Jan 26 06:03:00 +0000 2019\n",
      "RT @jeremyphoward: Practical Deep Learning for Coders, 2019 edition, is now available. With a shiny new video player with searchable transc…\n",
      "Fri Jan 25 16:59:06 +0000 2019\n",
      "RT @KirkDBorne: #Alibaba's #AI can generate 20,000 lines of copy in a second, and has even passed the #TuringTest: https://t.co/heJ2DGPzHa…\n",
      "Wed Jan 16 04:22:19 +0000 2019\n",
      "RT @KirkDBorne: 40+ Techniques Used by #DataScientists, with links to articles for every one of the techniques: https://t.co/VBNBR1bn91 #ab…\n",
      "Tue Jan 15 17:39:31 +0000 2019\n",
      "RT @TopCyberNews: #CES2019 #QuantumComputer!\n",
      "\n",
      "cc: @SPittWalker @ipfconline1 @SpirosMargaris @andi_staub @sallyeaves @HaroldSinnott @mclynd…\n",
      "Tue Jan 15 17:37:04 +0000 2019\n",
      "RT @KirkDBorne: #AI predictions for 2019 from Yann LeCun, Hilary Mason, Andrew Ng, and Rumman Chowdhury: https://t.co/xjzWut69uF\n",
      "\n",
      "#MachineL…\n",
      "Tue Jan 15 03:32:23 +0000 2019\n",
      "RT @odsc: The 50 best public datasets for #MachineLearning https://t.co/fjaauUN6ui\n",
      "Tue Jan 15 03:30:21 +0000 2019\n",
      "RT @FinMKTG: Disrupt or be disrupted - inside CEO’s brain 🧠 \n",
      "#DigitalTransformation #fintech #futureofwork \n",
      "\n",
      "HT @MikeQuindazzi v/ @helene_w…\n",
      "Tue Jan 15 03:30:03 +0000 2019\n",
      "RT @kaggle: 10 Predictions for Deep Learning in 2019 by  @IntuitMachine https://t.co/GgWF76Xjiq https://t.co/4FGJd8qp4l\n",
      "Thu Jan 10 17:36:17 +0000 2019\n",
      "RT @KirkDBorne: Continuous lifelong learning empowered with this Reading List for #DataScientists\n",
      "https://t.co/FVvs54Tttu #abdsc\n",
      "\n",
      "#BigData…\n",
      "Wed Jan 09 21:12:58 +0000 2019\n",
      "RT @alvinfoo: 7 Trends at #CES2019 \n",
      "\n",
      "#5G #smarthome #IOT #wearables #AutonomousVehicles #AR #DigitalTransformation \n",
      "\n",
      "@alison_iot @ipfconlin…\n",
      "Tue Jan 08 04:31:34 +0000 2019\n",
      "RT @PyImageSearch: New tutorial!🚀 Auto-Keras and AutoML: A Getting Started Guide\n",
      "- Automatically create + train #DeepLearning models\n",
      "- Zero…\n",
      "Tue Jan 08 04:30:18 +0000 2019\n",
      "RT @ipfconline1: One of The Greatest 2018 #MachineLearning Paper\n",
      "👇\n",
      "Large-Scale Study of Curiosity-Driven Learning\n",
      "\n",
      "https://t.co/VYNy1lcYRc…\n",
      "Tue Jan 08 04:30:07 +0000 2019\n",
      "RT @simonlporter: 3 basic steps to start-up your AI Business Strategy https://t.co/MlhbFUj40K\n",
      "Mon Jan 07 04:05:26 +0000 2019\n",
      "RT @KirkDBorne: Demystifying #AI — Explained In One Picture!\n",
      "\n",
      "+plus see more #BigData #DataScience \"Explained in One Picture\" articles and…\n",
      "Mon Dec 31 04:34:56 +0000 2018\n",
      "RT @MikeQuindazzi: #AI prepares to #HACK your brain &gt;&gt;&gt; @MikeQuindazzi &gt;&gt;&gt; #MachineLearning #DeepLearning #IoT #BigData #DataAnalytics #Mal…\n",
      "Mon Dec 31 04:34:42 +0000 2018\n",
      "RT @simonlporter: 50+ Examples of How Blockchains are Taking Over the World https://t.co/RV3c9j9lSd\n",
      "Sat Dec 29 05:22:52 +0000 2018\n",
      "RT @DD_Wen_: What Great Data Analysts Do — and Why Every Organization Needs Them \n",
      "https://t.co/BLD71Z6ZbR\n",
      "Sat Dec 29 05:19:47 +0000 2018\n",
      "RT @analyticbridge: Swarm Optimization: Goodbye Gradients https://t.co/QV4dQ9LxtB\n",
      "Sat Dec 29 05:18:54 +0000 2018\n",
      "RT @MHiesboeck: 🔴 Can you imagine 200 quadrillion calculations per second 🧠?\n",
      "\n",
      "@antgrasso @jeffkagan @psb_dc @cloudpreacher @DrJDrooghaag @F…\n",
      "Wed Dec 26 07:15:21 +0000 2018\n",
      "For us the learning will continue lifelong. https://t.co/FDQfoNpzwS\n",
      "Wed Dec 26 07:12:46 +0000 2018\n",
      "RT @TamaraMcCleary: Want to be a #DataScientist? 25 #DataScience skills. #MachineLearning #BigData #DataMining #Statistics #Cloud #programm…\n",
      "Wed Dec 26 07:12:22 +0000 2018\n",
      "RT @KirkDBorne: 7 Techniques for Data Dimensionality Reduction for #DataScientists: https://t.co/mGsy68rhiQ #abdsc \n",
      "\n",
      "#BigData #DataScience…\n",
      "Tue Dec 25 23:10:00 +0000 2018\n",
      "RT @KirkDBorne: Top Trends &amp; Expectations for #AI in 2019: https://t.co/aDLYkE992K by @analyticsinme HT @DeepLearn007 \n",
      "\n",
      "#XAI #MachineLearni…\n",
      "Mon Dec 24 14:31:53 +0000 2018\n",
      "RT @KirkDBorne: 4 Strategies to Deal With Large Datasets Using Pandas: https://t.co/J37CIh9x8e #DataScience #MachineLearning #BigData #Codi…\n",
      "Sun Dec 23 13:37:52 +0000 2018\n",
      "RT @IBMDeveloper: Get the Code: Use deep-learning algorithms to detect movement, and identify objects in a video feed. https://t.co/OMPwJV2…\n",
      "Sun Dec 23 13:36:53 +0000 2018\n",
      "RT @Ronald_vanLoon: #AI can be used to create a ‘master key’ that will fool fingerprint scanners.\n",
      "by @nowthisnews @MasterprintUK |\n",
      "\n",
      "#Artifi…\n",
      "Sat Dec 22 20:52:15 +0000 2018\n",
      "RT @NicolasPapernot: Our team @GoogleAI has just released a new library for training machine learning models with (differential) privacy fo…\n",
      "Sat Dec 22 20:51:49 +0000 2018\n",
      "RT @SamueL_WonG_: How Fast Is Artificial Intelligence Growing? Look At The Key Bellwethers via @forbes https://t.co/1s4JEV7mDi\n",
      "Sat Dec 22 20:51:03 +0000 2018\n",
      "I have always loved the idea of swarm robots..practical and efficient ...  better than humanoids https://t.co/okh5C8jruJ\n",
      "Sat Dec 22 20:48:54 +0000 2018\n",
      "Python it is. https://t.co/IaeH5xOR8Z\n",
      "Sat Dec 22 20:48:05 +0000 2018\n",
      "RT @KirkDBorne: The Ten Best Programming Languages to learn in 2019: https://t.co/AqaNfMSBTP #python #Rstats #java #javascript #coding #Dat…\n",
      "Sat Dec 22 20:47:47 +0000 2018\n",
      "RT @sheena2804: Great People to follow :\n",
      "#FF\n",
      "\n",
      "@evankirstel @SpirosMargaris @TamaraMcCleary @antgrasso  @ipfconline1 @JacBurns_Comext @MikeQ…\n",
      "Sat Dec 22 20:47:27 +0000 2018\n",
      "RT @BillGates: The books that kept me up reading in 2018: https://t.co/Up1rwhXV4G https://t.co/yaoBHNV4gR\n",
      "Sat Dec 22 20:46:42 +0000 2018\n",
      "RT @slashML: How do you keep track of all the updates in your field? Research, techniques, and programming. Very time consuming … https://t…\n",
      "Sat Dec 22 20:46:03 +0000 2018\n",
      "This is what we need in our cities https://t.co/akPsXHKSSk\n",
      "Sat Dec 22 20:44:23 +0000 2018\n",
      "RT @KirkDBorne: Breaking Through the Cost Barrier to #DeepLearning with Transfer Learning: https://t.co/s0RnuYNp95 #abdsc #BigData #DataSci…\n",
      "Thu Dec 20 12:38:03 +0000 2018\n",
      "RT @KirkDBorne: Top 20 #Python libraries for #DataScience in 2018: https://t.co/5dDTXZ0rzP #abdsc #Infographic by @ActiveWizards\n",
      "\n",
      "#BigData…\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec 20 12:36:11 +0000 2018\n",
      "RT @simonlporter: What The AI Jobs Of The Future Will Look Like https://t.co/xUiXQadLx3\n",
      "Thu Dec 20 12:35:22 +0000 2018\n",
      "RT @KirkDBorne: 5 trends to expect for artificial intelligence in 2019: https://t.co/cNfcjkXlbw #DeepLearning #MachineLearning #DataScience…\n",
      "Tue Dec 18 20:39:47 +0000 2018\n",
      "RT @TamaraMcCleary: Want to be a #DataScientist? 25 #DataScience skills. #MachineLearning #BigData #DataMining #Statistics #Cloud #programm…\n",
      "Tue Dec 18 12:21:55 +0000 2018\n",
      "RT @simonlporter: What Data Scientists Really Do, According to 35 Data Scientists https://t.co/mKFBQweNGH\n",
      "Tue Dec 18 12:21:42 +0000 2018\n",
      "RT @KirkDBorne: Cheat Sheets for #DataScientists — #DataScience, #MachineLearning, #Statistics, #DeepLearning, #DataViz +more (including R,…\n",
      "Mon Dec 17 13:34:45 +0000 2018\n",
      "RT @dataandme: 🤓 Oh so handy...\n",
      "\"Stanford CS 229 machine learning cheatsheets\"  👬 @afshinea &amp; @shervinea\n",
      "https://t.co/VKV2UGkWzN #MachineLe…\n",
      "Mon Dec 17 13:34:34 +0000 2018\n",
      "RT @DataCamp: This handy one-page cheat sheet presents the #Python basics that you need to perform data analysis!\n",
      "https://t.co/X2hUn97nqW h…\n",
      "Mon Dec 17 13:31:34 +0000 2018\n",
      "RT @simonlporter: A.I. and robotics will create almost 60 million more jobs than they destroy by 2022, report says https://t.co/gWOIamyBuY\n",
      "Mon Dec 17 13:31:19 +0000 2018\n",
      "RT @analyticbridge: 33 unusual problems that can be solved with data science https://t.co/fmCpOOXZB1\n",
      "Mon Dec 17 13:29:43 +0000 2018\n",
      "RT @KirkDBorne: Check out the 150+ excellent #DeepLearning resources, articles, infographics, and tutorials for #DataScientists that are av…\n",
      "Sat Dec 15 04:34:18 +0000 2018\n",
      "RT @slashML: Beyond imitation: Zero-shot task transfer on robots by learning concepts as cognitive programs https://t.co/g3vyL3mZ80\n",
      "Sat Dec 15 04:33:59 +0000 2018\n",
      "RT @DD_Wen_: Getting Value from Machine Learning Isn’t About Fancier Algorithms — It’s About Making It Easier to Use \n",
      "https://t.co/i24Ix9ta…\n",
      "Sat Dec 15 01:46:06 +0000 2018\n",
      "@KirkDBorne Been following your tweets for some time now. Must say...really good reasearch...A must follow for anyone interested in #Datascience #MachineLearning #AI Truly deserved No 1 spot.\n",
      "Sat Dec 15 01:43:36 +0000 2018\n",
      "RT @KirkDBorne: Colossal Collection of Cool &amp; Convenient Cheat Sheets for Curious #DataScientists — #DataScience, #MachineLearning, #Statis…\n",
      "Sat Dec 15 01:40:27 +0000 2018\n",
      "Now this is what we need in every school around the globe. https://t.co/TvDEAuQ8UP\n",
      "Fri Dec 14 16:39:07 +0000 2018\n",
      "RT @AndrewYNg: The AI Index 2018 report is out! Lots of great data. My key takeaways: (i) AI's rapid growth--in jobs, publications, perform…\n",
      "Fri Dec 14 15:30:49 +0000 2018\n",
      "RT @kdnuggets: A radical new #neuralnetwork design could solve #AI problems where data is continuous. \"Neural Ordinary Differential Equatio…\n",
      "Fri Dec 14 15:29:48 +0000 2018\n",
      "RT @Ronald_vanLoon: In 4 years your #Smartphone might be able to read your mind\n",
      "by @wef @IRO_ITB |\n",
      "\n",
      "#ArtificialIntelligence #AI #SmartTech…\n",
      "Fri Dec 14 15:27:32 +0000 2018\n",
      "RT @KirkDBorne: The #DataScience Mindmap for Managers: https://t.co/AXcaaq28q9 #abdsc \n",
      "\n",
      "#Analytics #BigData #DataAnalytics #AI #DAIFE #Mach…\n",
      "Thu Dec 13 11:33:11 +0000 2018\n",
      "RT @MHiesboeck: These are the most innovative and impactful #technologies around\n",
      "\n",
      "@chboursin @alvinfoo @kashthefuturist @MarTechExec @gratt…\n",
      "Thu Dec 13 01:11:58 +0000 2018\n",
      "RT @BillGates: This book is a must read for anyone interested in AI, machine learning, and machine vision. https://t.co/bOFgrnkORN\n",
      "Thu Dec 13 01:07:36 +0000 2018\n",
      "RT @DataScienceCtrl: 25 Timeless Data Science Articles https://t.co/IyBNpkCTCA\n",
      "Wed Dec 12 00:16:40 +0000 2018\n",
      "RT @HaroldSinnott: 🗣️Jack Ma : The best way to promote your company is not you, the #CEO. The best way is your product, your services and y…\n",
      "Wed Dec 12 00:10:04 +0000 2018\n",
      "Highly useful!! https://t.co/YXu3bgO4RD\n",
      "Wed Dec 12 00:08:10 +0000 2018\n",
      "The Catch-22 for aspiring data scientists, I quote @_brohrer_ \"New data scientists can’t show their qualifications because they’ve never had a data science job, and they can’t get a data science job because they can’t show their qualifications.\"\n",
      "Wed Dec 12 00:03:23 +0000 2018\n",
      "So General Adversarial Networks and AutoML seem to be the things to watch out for in 2019. https://t.co/0qGf5FQhPd\n",
      "Tue Dec 11 23:52:32 +0000 2018\n",
      "RT @schmarzo: Here's how #millennials should view the world of #DataScience. @HitachiVantara @CloudExpo @ipfconline1\n",
      "https://t.co/EAaH0hw1p…\n",
      "Tue Dec 11 23:46:10 +0000 2018\n",
      "RT @ipfconline1: The 4 Types of Artificial Intelligence: From Reactive to Self-Aware [Infographic]\n",
      "https://t.co/AgXBj9Aeir       v/ @Futuri…\n",
      "Tue Dec 11 21:11:54 +0000 2018\n",
      "RT @KirkDBorne: How To Start A #Startup (#Infographic) and Beginners Guide to Being an #Entrepreneur : https://t.co/ezIBFQSzKI by @ineedseo…\n",
      "Sat Dec 08 14:53:03 +0000 2018\n",
      "RT @KirkDBorne: #Blockchain infographic — 50+ real use cases: https://t.co/EhD7FKkDWE #abdsc #bitcoin #SmartContracts #DistributedLedger #D…\n",
      "Thu Dec 06 13:30:22 +0000 2018\n",
      "So these are the top skills-\n",
      "Programming : Python, JAVA, C++\n",
      "Statistical : Scala , SAS, R\n",
      "Visualization: Tableau\n",
      "Deep Learning: Tensorflow, PyTorch, Keras\n",
      "Data Engineering: SQL, Spark, Hadoop\n",
      "\n",
      "Great insights by George Liu https://t.co/WLs7A9Gix9\n",
      "Thu Dec 06 13:05:16 +0000 2018\n",
      "RT @alvinfoo: #AI will add $16 trillion to the global economy by 2030!\n",
      "\n",
      "#Fintech #Retail #DigitalTransformation #FutureofWork #iot\n",
      "\n",
      "@MicWon…\n",
      "Thu Dec 06 13:05:06 +0000 2018\n",
      "RT @chboursin: #WearableTech screen wraps around your arm &gt;&gt;&gt; @futurism via @MikeQuindazzi &gt;&gt;&gt; #Innovation #Mobile #IoT #AI #Wearables #5G…\n",
      "Sat Dec 01 21:35:32 +0000 2018\n",
      "RT @Ronald_vanLoon: These 100 Companies Are Leading the Way in A.I.\n",
      "by @nick_rapp @brianbokeefe @FortuneMagazine |\n",
      "\n",
      "#MachineLearning #ML #D…\n",
      "Sat Dec 01 21:30:35 +0000 2018\n",
      "Excellent !! https://t.co/bNjjQ1fkVB\n",
      "Sat Dec 01 11:57:07 +0000 2018\n",
      "So true 😂😂 https://t.co/jmLm88in8P\n",
      "Tue Nov 27 01:46:01 +0000 2018\n",
      "RT @grattonboy: Ten types of #AI technologies advancing in 2018 @MikeQuindazzi #ArtificialIntelligence #AI #DeepLearning MT @jblefevre60➡️h…\n",
      "Tue Nov 27 01:43:35 +0000 2018\n",
      "RT @Ronald_vanLoon: A china-made holographic #3D projection device will be showcased\n",
      "by @CCTV_Plus |\n",
      "\n",
      "#InternetOfThings #IoT #Smarttech #3D…\n",
      "Mon Nov 26 18:30:50 +0000 2018\n",
      "RT @DataScienceCtrl: What pays most: R, Python, or SQL? https://t.co/BJVXDttvZp\n",
      "Mon Nov 26 18:30:27 +0000 2018\n",
      "RT @KirkDBorne: The 2018 #BigData and #AI Landscape: https://t.co/J58CCQKmNy by @MattTurck \n",
      "\n",
      "#DataScience #Analytics #MachineLearning #Deep…\n",
      "Fri Nov 23 14:49:12 +0000 2018\n",
      "RT @KirkDBorne: 20 Great Articles about #AI, #MachineLearning, and #DeepLearning: https://t.co/pwCoRw7bLd #abdsc \n",
      "\n",
      "#BigData #DataScience #N…\n",
      "Fri Nov 23 14:45:37 +0000 2018\n",
      "@randal_olson Excellent\n",
      "Fri Nov 23 14:44:27 +0000 2018\n",
      "RT @odsc: Take a look into Uber’s Michelangelo PyML, a platform that enables rapid Python ML model development. #AI #ODSC https://t.co/xs3V…\n",
      "Tue Nov 20 23:34:40 +0000 2018\n",
      "RT @KirkDBorne: Breakthrough Neural Network paves the way for Quantum #AI: https://t.co/h9z6V4disj\n",
      "\n",
      "Read more about it here: https://t.co/D…\n",
      "Mon Nov 19 13:19:07 +0000 2018\n",
      "RT @odsc: Deloitte: ‘Pervasive’ AI promises to transform agriculture, health care, and manufacturing #AI #ODSC https://t.co/mW1pVsV5qJ\n",
      "Mon Nov 19 11:59:31 +0000 2018\n",
      "RT @KirkDBorne: Comprehensive Repository of #DataScience Resources, including “Four Great Pictures Illustrating #MachineLearning Concepts”…\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for status in tweepy.Cursor(api.user_timeline, screename='elonmusk', tweet_mode='extended').items(200):\n",
    "    print(status._json['created_at'])\n",
    "    print(status._json['full_text'])\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 17 12:51:44 +0000 2019\n",
      "Tue Apr 02 13:23:50 +0000 2019\n",
      "Tue Apr 02 13:16:57 +0000 2019\n",
      "Mon Apr 01 21:20:31 +0000 2019\n",
      "Wed Mar 13 16:03:08 +0000 2019\n",
      "Sun Mar 03 16:17:20 +0000 2019\n",
      "Tue Feb 26 13:52:11 +0000 2019\n",
      "Sat Feb 23 05:53:33 +0000 2019\n",
      "Sat Feb 23 05:50:07 +0000 2019\n",
      "Sat Feb 23 05:47:12 +0000 2019\n",
      "Sat Feb 23 05:41:41 +0000 2019\n",
      "Sat Feb 23 05:38:53 +0000 2019\n",
      "Sat Feb 23 05:35:39 +0000 2019\n",
      "Fri Feb 15 16:33:25 +0000 2019\n",
      "Fri Feb 15 16:29:24 +0000 2019\n",
      "Fri Feb 15 15:41:31 +0000 2019\n",
      "Fri Feb 15 15:39:54 +0000 2019\n",
      "Mon Feb 11 16:08:39 +0000 2019\n",
      "Mon Feb 11 16:04:25 +0000 2019\n",
      "Mon Feb 11 16:04:18 +0000 2019\n",
      "Fri Feb 01 22:51:24 +0000 2019\n",
      "Fri Feb 01 20:23:05 +0000 2019\n",
      "Sat Jan 26 06:05:22 +0000 2019\n",
      "Sat Jan 26 06:03:00 +0000 2019\n",
      "Fri Jan 25 16:59:06 +0000 2019\n",
      "Wed Jan 16 04:22:19 +0000 2019\n",
      "Tue Jan 15 17:39:31 +0000 2019\n",
      "Tue Jan 15 17:37:04 +0000 2019\n",
      "Tue Jan 15 03:32:23 +0000 2019\n",
      "Tue Jan 15 03:30:21 +0000 2019\n",
      "Tue Jan 15 03:30:03 +0000 2019\n",
      "Thu Jan 10 17:36:17 +0000 2019\n",
      "Wed Jan 09 21:12:58 +0000 2019\n",
      "Tue Jan 08 04:31:34 +0000 2019\n",
      "Tue Jan 08 04:30:18 +0000 2019\n",
      "Tue Jan 08 04:30:07 +0000 2019\n",
      "Mon Jan 07 04:05:26 +0000 2019\n",
      "Mon Dec 31 04:34:56 +0000 2018\n",
      "Mon Dec 31 04:34:42 +0000 2018\n",
      "Sat Dec 29 05:22:52 +0000 2018\n",
      "Sat Dec 29 05:19:47 +0000 2018\n",
      "Sat Dec 29 05:18:54 +0000 2018\n",
      "Wed Dec 26 07:15:21 +0000 2018\n",
      "Wed Dec 26 07:12:46 +0000 2018\n",
      "Wed Dec 26 07:12:22 +0000 2018\n",
      "Tue Dec 25 23:10:00 +0000 2018\n",
      "Mon Dec 24 14:31:53 +0000 2018\n",
      "Sun Dec 23 13:37:52 +0000 2018\n",
      "Sun Dec 23 13:36:53 +0000 2018\n",
      "Sat Dec 22 20:52:15 +0000 2018\n",
      "Sat Dec 22 20:51:49 +0000 2018\n",
      "Sat Dec 22 20:51:03 +0000 2018\n",
      "Sat Dec 22 20:48:54 +0000 2018\n",
      "Sat Dec 22 20:48:05 +0000 2018\n",
      "Sat Dec 22 20:47:47 +0000 2018\n",
      "Sat Dec 22 20:47:27 +0000 2018\n",
      "Sat Dec 22 20:46:42 +0000 2018\n",
      "Sat Dec 22 20:46:03 +0000 2018\n",
      "Sat Dec 22 20:44:23 +0000 2018\n",
      "Thu Dec 20 12:38:03 +0000 2018\n",
      "Thu Dec 20 12:36:11 +0000 2018\n",
      "Thu Dec 20 12:35:22 +0000 2018\n",
      "Tue Dec 18 20:39:47 +0000 2018\n",
      "Tue Dec 18 12:21:55 +0000 2018\n",
      "Tue Dec 18 12:21:42 +0000 2018\n",
      "Mon Dec 17 13:34:45 +0000 2018\n",
      "Mon Dec 17 13:34:34 +0000 2018\n",
      "Mon Dec 17 13:31:34 +0000 2018\n",
      "Mon Dec 17 13:31:19 +0000 2018\n",
      "Mon Dec 17 13:29:43 +0000 2018\n",
      "Sat Dec 15 04:34:18 +0000 2018\n",
      "Sat Dec 15 04:33:59 +0000 2018\n",
      "Sat Dec 15 01:46:06 +0000 2018\n",
      "Sat Dec 15 01:43:36 +0000 2018\n",
      "Sat Dec 15 01:40:27 +0000 2018\n",
      "Fri Dec 14 16:39:07 +0000 2018\n",
      "Fri Dec 14 15:30:49 +0000 2018\n",
      "Fri Dec 14 15:29:48 +0000 2018\n",
      "Fri Dec 14 15:27:32 +0000 2018\n",
      "Thu Dec 13 11:33:11 +0000 2018\n",
      "Thu Dec 13 01:11:58 +0000 2018\n",
      "Thu Dec 13 01:07:36 +0000 2018\n",
      "Wed Dec 12 00:16:40 +0000 2018\n",
      "Wed Dec 12 00:10:04 +0000 2018\n",
      "Wed Dec 12 00:08:10 +0000 2018\n",
      "Wed Dec 12 00:03:23 +0000 2018\n",
      "Tue Dec 11 23:52:32 +0000 2018\n",
      "Tue Dec 11 23:46:10 +0000 2018\n",
      "Tue Dec 11 21:11:54 +0000 2018\n",
      "Sat Dec 08 14:53:03 +0000 2018\n",
      "Thu Dec 06 13:30:22 +0000 2018\n",
      "Thu Dec 06 13:05:16 +0000 2018\n",
      "Thu Dec 06 13:05:06 +0000 2018\n",
      "Sat Dec 01 21:35:32 +0000 2018\n",
      "Sat Dec 01 21:30:35 +0000 2018\n",
      "Sat Dec 01 11:57:07 +0000 2018\n",
      "Tue Nov 27 01:46:01 +0000 2018\n",
      "Tue Nov 27 01:43:35 +0000 2018\n",
      "Mon Nov 26 18:30:50 +0000 2018\n",
      "Mon Nov 26 18:30:27 +0000 2018\n",
      "Fri Nov 23 14:49:12 +0000 2018\n",
      "Fri Nov 23 14:45:37 +0000 2018\n",
      "Fri Nov 23 14:44:27 +0000 2018\n",
      "Tue Nov 20 23:34:40 +0000 2018\n",
      "Mon Nov 19 13:19:07 +0000 2018\n",
      "Mon Nov 19 11:59:31 +0000 2018\n"
     ]
    }
   ],
   "source": [
    "for status in tweepy.Cursor(api.user_timeline, screename='@elonmusk', tweet_mode='extended').items(200):\n",
    "    print(status._json['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
